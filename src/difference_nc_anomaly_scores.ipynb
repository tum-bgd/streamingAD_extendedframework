{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f811d0cc-6348-4136-a5e6-3f189882c952",
   "metadata": {},
   "source": [
    "# Difference in nonconformity and anomaly scores\n",
    "This script evaluates anomaly detection algorithms based on their capability to differentiate between normal and anomalous segments in a time series. For this purpose, the nonconformity and anomaly scores are analyzed for an anomalous segment, compared to the average score level directly before the anomaly. Anomalies can be labeled anomalies found in benchmark datasets or artificially introduced anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f9c50c1-9631-435d-bd16-a2b1b098ed50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from models.gnn_ensembles import EnsembleGNNWrapper\n",
    "from training_set_update.slidingWindow import sliding_window as sw_helper\n",
    "from nonconformity_scores.nonconformity_wrapper import calc_nonconformity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae17cdc-0bbc-4299-9601-435b72c0363a",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53dba88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_preceding_interval_anomaly = 100\n",
    "preceding_anomaly_interval_length = 50\n",
    "preceding_offset = preceding_anomaly_interval_length + buffer_preceding_interval_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64456b69-2f63-4474-8f35-b6359a6b4537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_representation_length, dataset_category = 100, 'multivariate'\n",
    "collection_id = 'Daphnet'\n",
    "model_id = 'ensemble_gnn'\n",
    "ls_id, anomaly_score_id = 'ares_al_ks', 'anomaly_likelihood'\n",
    "run_date_id = '20240304_112528'\n",
    "output_folder_path = f'../out/{collection_id}'\n",
    "data_folder_base_path = f'../data/{dataset_category}/{collection_id}'\n",
    "dataset_ids = sorted([x for x in os.listdir(output_folder_path) if not x.startswith('.')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec862f33-68f0-4880-b173-12a7c5594b85",
   "metadata": {},
   "source": [
    "## Analyze nonconformity scores after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89efe8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anomaly_sequences(target):\n",
    "    anomaly_sequences = []\n",
    "    anomaly_indices = np.unique(np.where(target == 1)[0])\n",
    "    change_ind = np.where(np.diff(anomaly_indices) != 1)[0] + 1\n",
    "    if len(change_ind) != 0:\n",
    "        sequences = np.split(anomaly_indices, change_ind)\n",
    "    else:\n",
    "        sequences = [anomaly_indices]\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) != 0:\n",
    "            anomaly_sequences.append([np.min(sequence), np.max(sequence)])\n",
    "    return anomaly_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5eb0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(start1, end1, start2, end2):\n",
    "    \"\"\"Does the range (start1, end1) overlap with (start2, end2)?\"\"\"\n",
    "    return not (end1 < start2 or end2 < start1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e90b45ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now at dataset S01R01E0\n",
      "Now at dataset S01R01E1\n",
      "Now at dataset S01R02E0\n",
      "Now at dataset S02R01E0\n",
      "Now at dataset S02R02E0\n",
      "Now at dataset S03R01E0\n",
      "Now at dataset S03R01E1\n",
      "Now at dataset S03R02E0\n",
      "Now at dataset S03R03E0\n",
      "Now at dataset S03R03E1\n",
      "Now at dataset S03R03E2\n",
      "Now at dataset S03R03E3\n",
      "Now at dataset S03R03E4\n",
      "Now at dataset S04R01E0\n",
      "Now at dataset S04R01E1\n",
      "Now at dataset S05R01E0\n",
      "Now at dataset S05R01E1\n",
      "Now at dataset S05R01E2\n",
      "Now at dataset S05R01E3\n",
      "Now at dataset S05R02E0\n",
      "Now at dataset S05R02E1\n",
      "Now at dataset S06R01E0\n",
      "Now at dataset S06R01E1\n",
      "Now at dataset S06R01E2\n",
      "Now at dataset S06R02E0\n",
      "Now at dataset S06R02E1\n",
      "Now at dataset S07R01E0\n",
      "Now at dataset S07R02E0\n",
      "Now at dataset S08R01E0\n",
      "Now at dataset S08R01E1\n",
      "Now at dataset S08R01E2\n",
      "Now at dataset S08R01E3\n",
      "Now at dataset S09R01E0\n",
      "Now at dataset S09R01E1\n",
      "Now at dataset S09R01E2\n",
      "Now at dataset S09R01E3\n",
      "Now at dataset S09R01E4\n",
      "Now at dataset S10R01E0\n",
      "Now at dataset S10R01E1\n"
     ]
    }
   ],
   "source": [
    "results_total = {}\n",
    "for dataset_id in dataset_ids:\n",
    "    print(f\"Now at dataset {dataset_id}\")\n",
    "    results = {}\n",
    "    test_data = pd.read_csv(f'{data_folder_base_path}/{dataset_id}.test.csv')\n",
    "    labels = test_data['is_anomaly'].to_numpy()\n",
    "    if len(np.unique(labels)) == 1:\n",
    "        continue\n",
    "    true_anomaly_sequences = calculate_anomaly_sequences(labels)\n",
    "    artificial_anomalies_path = f'{output_folder_path}/{dataset_id}/artificial_anomalies/{run_date_id}'\n",
    "    artificial_anomaly_sequences = [[int(x.group()) for x in re.finditer(r'\\d+', fn)] for fn in os.listdir(artificial_anomalies_path) if not fn.startswith('.')]\n",
    "    all_anomaly_sequences = artificial_anomaly_sequences + true_anomaly_sequences\n",
    "    approaches_paths = [x for x in os.listdir(f'{output_folder_path}/{dataset_id}') if not x.startswith('.') and not x in ['initial_weights', 'artificial_anomalies']]\n",
    "    for approach_path in approaches_paths:\n",
    "        model_id, learning_strategy_id, anomaly_score_id = approach_path.split('-')\n",
    "        if model_id not in results.keys():\n",
    "            results[model_id] = {}\n",
    "        if learning_strategy_id not in results[model_id].keys():\n",
    "            results[model_id][learning_strategy_id] = {}\n",
    "        if anomaly_score_id not in results[model_id][learning_strategy_id].keys():\n",
    "            results[model_id][learning_strategy_id][anomaly_score_id] = []\n",
    "        score_path = f'{output_folder_path}/{dataset_id}/{approach_path}/{run_date_id}'\n",
    "        anomaly_scores = pd.read_csv(f'{score_path}/anomaly_scores.csv').to_numpy()\n",
    "        nonconformity_scores = pd.read_csv(f'{score_path}/nonconformity_scores.csv').to_numpy()\n",
    "        offset = int(anomaly_scores[0, 0])\n",
    "\n",
    "        # compare anomaly maximum nc/anomaly score to previous average (check that this sequence is not actually another previous anomaly) and save in results dict\n",
    "        for seq in all_anomaly_sequences:\n",
    "            start, end = seq[0] - offset, seq[1] + 1 - offset\n",
    "            if start - preceding_offset < 0:\n",
    "                continue\n",
    "            max_anomaly_score = anomaly_scores[start:end, 1].max()\n",
    "            max_nonconformity_score = nonconformity_scores[start:end, 1].max()\n",
    "            if not any([overlap(seq[0] - preceding_offset, seq[0] - 1, seq2[0], seq2[1]) for seq2 in all_anomaly_sequences]):\n",
    "                # print(f'Anomaly sequence: {seq[0]} - {seq[1]}')\n",
    "                preceding_anomaly_mean = np.mean(anomaly_scores[start - preceding_offset : start - buffer_preceding_interval_anomaly, 1])\n",
    "                preceding_nonconformity_mean = np.mean(nonconformity_scores[start - preceding_offset : start - buffer_preceding_interval_anomaly, 1])\n",
    "            else:\n",
    "                # print(f'Skipping anomaly sequence: {seq[0]} - {seq[1]}')\n",
    "                continue\n",
    "            results[model_id][learning_strategy_id][anomaly_score_id].append({\n",
    "                \"anomaly_sequence\": str(seq),\n",
    "                \"is_artificial\": seq in artificial_anomaly_sequences,\n",
    "                \"preceding_anomaly_mean\": preceding_anomaly_mean,\n",
    "                \"max_anomaly_score\": max_anomaly_score,\n",
    "                \"preceding_nonconformity_mean\": preceding_nonconformity_mean,\n",
    "                \"max_nonconformity_score\": max_nonconformity_score,\n",
    "            })\n",
    "        \n",
    "    results_total[dataset_id] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "317157dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output_folder_path}/results_difference_nc_anomaly_scores.json', 'w') as file:\n",
    "    json.dump(results_total, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf077971",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "Calculate absolute and relative difference averaged over all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ba094fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {'as_abs': [], 'as_rel': [], 'nc_abs': [], 'nc_rel': []}\n",
    "template_outer = {\n",
    "    'artificial_anomalies': deepcopy(template),\n",
    "    'real_anomalies': deepcopy(template),\n",
    "    'all_anomalies': deepcopy(template)\n",
    "}\n",
    "results_post_processing = {\n",
    "    'models': {},\n",
    "    'learning_strategies': {},\n",
    "    'models_learning_strategies': {}\n",
    "}\n",
    "for dataset_id in results_total.keys():\n",
    "    approaches_paths = [x for x in os.listdir(f'{output_folder_path}/{dataset_id}') if not x.startswith('.') and not x in ['initial_weights', 'artificial_anomalies']]\n",
    "    for approach_path in approaches_paths:\n",
    "        model_id, learning_strategy_id, anomaly_score_id = approach_path.split('-')\n",
    "        model_ls_id = f'{model_id}-{learning_strategy_id}'\n",
    "        if anomaly_score_id == 'confidence_levels':\n",
    "            continue\n",
    "        if model_id not in results_post_processing['models'].keys():\n",
    "            results_post_processing['models'][model_id] = deepcopy(template_outer)\n",
    "        if learning_strategy_id not in results_post_processing['learning_strategies'].keys():\n",
    "            results_post_processing['learning_strategies'][learning_strategy_id] = deepcopy(template_outer)\n",
    "        if model_ls_id not in results_post_processing['models_learning_strategies'].keys():\n",
    "            results_post_processing['models_learning_strategies'][model_ls_id] = deepcopy(template_outer)\n",
    "        for dict_key, obj_id in [('models', model_id), ('learning_strategies', learning_strategy_id), ('models_learning_strategies', model_ls_id)]:\n",
    "            for anomaly_entry in results_total[dataset_id][model_id][learning_strategy_id][anomaly_score_id]:\n",
    "                if anomaly_entry['is_artificial']:\n",
    "                    anomaly_categories = ['artificial_anomalies', 'all_anomalies']\n",
    "                else:\n",
    "                    anomaly_categories = ['real_anomalies', 'all_anomalies']\n",
    "                for anomaly_category in anomaly_categories:\n",
    "                    results_post_processing[dict_key][obj_id][anomaly_category]['as_abs'].append(anomaly_entry['max_anomaly_score'] - anomaly_entry['preceding_anomaly_mean'])\n",
    "                    results_post_processing[dict_key][obj_id][anomaly_category]['as_rel'].append(anomaly_entry['max_anomaly_score'] / anomaly_entry['preceding_anomaly_mean'] - 1.0)\n",
    "                    results_post_processing[dict_key][obj_id][anomaly_category]['nc_abs'].append(anomaly_entry['max_nonconformity_score'] - anomaly_entry['preceding_nonconformity_mean'])\n",
    "                    results_post_processing[dict_key][obj_id][anomaly_category]['nc_rel'].append(anomaly_entry['max_nonconformity_score'] / anomaly_entry['preceding_nonconformity_mean'] - 1.0)\n",
    "                \n",
    "       \n",
    "# Average across categories\n",
    "for dict_key in results_post_processing.keys():\n",
    "    for obj_key in results_post_processing[dict_key].keys():\n",
    "        for anomaly_category in template_outer.keys():\n",
    "            for score_key in template.keys():\n",
    "                results_post_processing[dict_key][obj_key][anomaly_category][score_key] = sum(results_post_processing[dict_key][obj_key][anomaly_category][score_key]) / max(1, len(results_post_processing[dict_key][obj_key][anomaly_category][score_key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5487ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output_folder_path}/results_post_processing_difference_nc_anomaly_scores.json', 'w') as file:\n",
    "    json.dump(results_post_processing, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c77f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('.streamingADENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "b53ad4e6ecf90fd6d913cf6b107c2a117277284f0518724314a77102f61b9f56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
